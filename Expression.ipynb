{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "275c195f-0587-4b7f-9efa-b654cc3ff140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Expression language : whenever a pyspark function is not found, we can use a SQL statement inside a pyspark statement using the Expresion language\n",
    "#syntax : expr(\"SQL STATEMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dfbb15b-677a-4335-8226-043914933cb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-------+-----+------+\n|  firstname|        lastname|country|state|salary|\n+-----------+----------------+-------+-----+------+\n|      James|           Smith|    USA|     |  3000|\n|    Michael|            Rose|    USA|   NY|  2500|\n|     Robert|        Williams|    USA|   CA|  6000|\n|      mARIA|Jones           |    USA|   FL| 20000|\n|      james|        Anderson|     UK|  LND|  8000|\n|    MICHEAL|           Bevon|     UK|  LND|  3500|\n|     Robert|         Patrick|     UK|  MCR|  2800|\n|      Maria|        Gonzales|     UK|  MCR|  7000|\n+-----------+----------------+-------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#create a dataframe from a static list\n",
    "# synatx: spark.createDataFrame(data = <list> , schema =<schemalist>)\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "staticlist = [(\"    James\",\"Smith\",\"USA\",\"\",3000),\n",
    "    (\"    Michael\",\"Rose\",\"USA\",\"NY\",2500),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\",6000),\n",
    "    (\"mARIA\",\"Jones           \",\"USA\",\"FL\",20000),\n",
    "    (\"james\",\"Anderson\",\"UK\",\"LND\",8000),\n",
    "    (\"MICHEAL\",\"Bevon\",\"UK\",\"LND\",3500),\n",
    "    (\"Robert\",\"Patrick\",\"UK\",\"MCR\",2800),\n",
    "    (\"Maria\",\"Gonzales\",\"UK\",\"MCR\",7000)   \n",
    "  ]\n",
    "\n",
    "columns = [\"firstname\", \"lastname\", \"country\", \"state\", \"salary\"]\n",
    "df = spark.createDataFrame( data=staticlist,  schema=columns )\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94ff32b0-2f61-43ba-899f-5aaad8cb64f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-------+-----+------+-------------+\n|  firstname|        lastname|country|state|salary|  New_country|\n+-----------+----------------+-------+-----+------+-------------+\n|      James|           Smith|    USA|     |  3000|United States|\n|    Michael|            Rose|    USA|   NY|  2500|United States|\n|     Robert|        Williams|    USA|   CA|  6000|United States|\n|      mARIA|Jones           |    USA|   FL| 20000|United States|\n|      james|        Anderson|     UK|  LND|  8000|           UK|\n|    MICHEAL|           Bevon|     UK|  LND|  3500|           UK|\n|     Robert|         Patrick|     UK|  MCR|  2800|           UK|\n|      Maria|        Gonzales|     UK|  MCR|  7000|           UK|\n+-----------+----------------+-------+-----+------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Replace USQ with United States\n",
    "from pyspark.sql.functions import *\n",
    "df2 = df.withColumn(\"New_country\",expr(\"case when country = 'USA' then 'United States' else country end\"))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04d2ebda-311f-4297-8c81-a2732efac223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-------+-----+------+-------------+\n|  firstname|        lastname|country|state|salary|  New_country|\n+-----------+----------------+-------+-----+------+-------------+\n|      James|           Smith|    USA|     |  3000|United States|\n|    Michael|            Rose|    USA|   NY|  2500|United States|\n|     Robert|        Williams|    USA|   CA|  6000|United States|\n|      mARIA|Jones           |    USA|   FL| 20000|United States|\n|      james|        Anderson|     UK|  LND|  8000|           UK|\n|    MICHEAL|           Bevon|     UK|  LND|  3500|           UK|\n|     Robert|         Patrick|     UK|  MCR|  2800|           UK|\n|      Maria|        Gonzales|     UK|  MCR|  7000|           UK|\n+-----------+----------------+-------+-----+------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "df2 = df.withColumn(\"New_country\",expr(\"replace(country,'USA','United States' )\"))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9c58555-bfda-4ed3-920f-4ac0de275389",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Date Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6f33e2f-e8d8-4a1d-9ee1-bf77c9fb19eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+\n|S_no|Start_Date|  End_Date|\n+----+----------+----------+\n|   1|2024-02-07|12/31/2024|\n|   2|2023-02-08|11/30/2024|\n|   3|2025-05-09|08/29/2025|\n|   4|2025-02-10|10/30/2025|\n|   5|2023-12-11|12/31/2023|\n|   6|2022-01-01|12/31/2022|\n|   7|2024-01-31|03/31/2024|\n+----+----------+----------+\n\nroot\n |-- S_no: long (nullable = true)\n |-- Start_Date: string (nullable = true)\n |-- End_Date: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import *\n",
    "data = [\n",
    "  (1, '2024-02-07', '12/31/2024'),\n",
    "  (2, '2023-02-08', '11/30/2024'),\n",
    "  (3, '2025-05-09', '08/29/2025'),\n",
    "  (4, '2025-02-10', '10/30/2025'),\n",
    "  (5, '2023-12-11', '12/31/2023'),\n",
    "  (6, '2022-01-01', '12/31/2022'),\n",
    "  (7, '2024-01-31', '03/31/2024')\n",
    "]\n",
    "col = ['S_no','Start_Date','End_Date']\n",
    "df = spark.createDataFrame(data=data,schema=col)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31909f05-33cd-449c-a664-833ff7d58df2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------+\n|S_no|Start_Date|End_Date|\n+----+----------+--------+\n|   1|2024-02-07|    NULL|\n|   2|2024-02-08|    NULL|\n|   3|2025-05-09|    NULL|\n|   4|2025-02-10|    NULL|\n|   5|2023-12-11|    NULL|\n|   6|2022-01-01|    NULL|\n|   7|2024-01-31|    NULL|\n+----+----------+--------+\n\nroot\n |-- S_no: long (nullable = true)\n |-- Start_Date: date (nullable = true)\n |-- End_Date: date (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#cast a string data type to date type\n",
    "#cast to a date will return a value if the string is in yyyy-mm-dd format. Any other format, it will return null.\n",
    "#use to_date function to handle other format scenarious\n",
    "\n",
    "df_cast = df.withColumn(\"Start_Date\",df.Start_Date.cast(DateType()))\\\n",
    "            .withColumn(\"End_Date\",to_date(df.End_Date.cast(DateType())))\n",
    "df_cast.show()\n",
    "df_cast.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd72d720-4484-467f-9035-bbe58810f79c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+\n|S_no|start_date|  end_date|\n+----+----------+----------+\n|   1|2024-02-07|2024-12-31|\n|   2|2024-02-08|2024-11-30|\n|   3|2025-05-09|2025-08-29|\n|   4|2025-02-10|2025-10-30|\n|   5|2023-12-11|2023-12-31|\n|   6|2022-01-01|2022-12-31|\n|   7|2024-01-31|2024-03-31|\n+----+----------+----------+\n\nroot\n |-- S_no: long (nullable = true)\n |-- start_date: date (nullable = true)\n |-- end_date: date (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# to handle above scenario, use to_date function\n",
    "#use todate to convert the string into a date format\n",
    "# syntax: to_date(\"DATECOL\",\"dateformat\")\n",
    "#to_date doesnt required any optionalstring format if the current string is in yyyy-mm-dd format. if the string date is any other format,optional string is madatory  \n",
    "\n",
    "df_cast = df.withColumn(\"start_date\",df.Start_Date.cast(DateType()))\\\n",
    "            .withColumn(\"end_date\",to_date(\"End_Date\",\"MM/dd/yyyy\"))\n",
    "df_cast.show()\n",
    "df_cast.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c8b9856-4d68-4674-ade3-e107942f259f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+----+-----+-------+---+-----------+-----------+------------+\n|S_no|Start_Date|  End_Date|YEAR|MONTH|QUARTER|DAY|DAY_OF_WEEK|DAY_OF_YEAR|WEEK_OF_YEAR|\n+----+----------+----------+----+-----+-------+---+-----------+-----------+------------+\n|   1|2024-02-07|12/31/2024|2024|    2|      1|  7|          4|         38|           6|\n|   2|2024-02-08|11/30/2024|2024|    2|      1|  8|          5|         39|           6|\n|   3|2025-05-09|08/29/2025|2025|    5|      2|  9|          6|        129|          19|\n|   4|2025-02-10|10/30/2025|2025|    2|      1| 10|          2|         41|           7|\n|   5|2023-12-11|12/31/2023|2023|   12|      4| 11|          2|        345|          50|\n|   6|2022-01-01|12/31/2022|2022|    1|      1|  1|          7|          1|          52|\n|   7|2024-01-31|03/31/2024|2024|    1|      1| 31|          4|         31|           5|\n+----+----------+----------+----+-----+-------+---+-----------+-----------+------------+\n\nroot\n |-- S_no: long (nullable = true)\n |-- Start_Date: string (nullable = true)\n |-- End_Date: string (nullable = true)\n |-- YEAR: integer (nullable = true)\n |-- MONTH: integer (nullable = true)\n |-- QUARTER: integer (nullable = true)\n |-- DAY: integer (nullable = true)\n |-- DAY_OF_WEEK: integer (nullable = true)\n |-- DAY_OF_YEAR: integer (nullable = true)\n |-- WEEK_OF_YEAR: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#get year, month,quarter,day etc..\n",
    "\n",
    "df_dates =df.withColumn(\"YEAR\",year(\"start_date\"))\\\n",
    "            .withColumn(\"MONTH\",month(\"start_date\"))\\\n",
    "            .withColumn(\"QUARTER\",quarter(\"start_date\"))\\\n",
    "            .withColumn(\"DAY\",dayofmonth(\"start_date\"))\\\n",
    "            .withColumn(\"DAY_OF_WEEK\",dayofweek(\"start_date\"))\\\n",
    "            .withColumn(\"DAY_OF_YEAR\",dayofyear(\"start_date\"))\\\n",
    "            .withColumn(\"WEEK_OF_YEAR\",weekofyear(\"start_date\"))\n",
    "df_dates.show()\n",
    "df_dates.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16e374da-abe6-43eb-a025-7bccaf24abff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+----------+\n|S_no|Start_Date|  End_Date| Add2_days|\n+----+----------+----------+----------+\n|   1|2024-02-07|12/31/2024|2024-02-09|\n|   2|2024-02-08|11/30/2024|2024-02-10|\n|   3|2025-05-09|08/29/2025|2025-05-11|\n|   4|2025-02-10|10/30/2025|2025-02-12|\n|   5|2023-12-11|12/31/2023|2023-12-13|\n|   6|2022-01-01|12/31/2022|2022-01-03|\n|   7|2024-01-31|03/31/2024|2024-02-02|\n+----+----------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Add date to existing Dates\n",
    "df_add1 = df.withColumn(\"Add2_days\", date_add(\"start_date\",2))\n",
    "df_add1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74a15359-5588-4dac-9e19-e899d9cf6b46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+----------+\n|S_no|Start_Date|  End_Date| rem2_days|\n+----+----------+----------+----------+\n|   1|2024-02-07|12/31/2024|2024-02-05|\n|   2|2024-02-08|11/30/2024|2024-02-06|\n|   3|2025-05-09|08/29/2025|2025-05-07|\n|   4|2025-02-10|10/30/2025|2025-02-08|\n|   5|2023-12-11|12/31/2023|2023-12-09|\n|   6|2022-01-01|12/31/2022|2021-12-30|\n|   7|2024-01-31|03/31/2024|2024-01-29|\n+----+----------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "#rEMOVE dAYS FROM EXISTING DATE\n",
    "df_rem = df.withColumn(\"rem2_days\", date_sub(\"start_date\",2))\n",
    "df_rem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17f7ac67-9558-44fb-9992-62c2baad32e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+-----------+-----------+\n|S_no|Start_Date|  End_Date|Add2_months|rem2_months|\n+----+----------+----------+-----------+-----------+\n|   1|2024-02-07|12/31/2024| 2024-04-07| 2023-12-07|\n|   2|2024-02-08|11/30/2024| 2024-04-08| 2023-12-08|\n|   3|2025-05-09|08/29/2025| 2025-07-09| 2025-03-09|\n|   4|2025-02-10|10/30/2025| 2025-04-10| 2024-12-10|\n|   5|2023-12-11|12/31/2023| 2024-02-11| 2023-10-11|\n|   6|2022-01-01|12/31/2022| 2022-03-01| 2021-11-01|\n|   7|2024-01-31|03/31/2024| 2024-03-31| 2023-11-30|\n+----+----------+----------+-----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "#add/Remove months to existing date\n",
    "#for year, quarter,Half year use multiples of months as we dont have a direct dateadd function for year, quarter month\n",
    "#2year = 24 months, 2 quarters = 5 months\n",
    "\n",
    "df_add2 = df.withColumn(\"Add2_months\", add_months(\"start_date\",2))\\\n",
    "            .withColumn(\"rem2_months\", add_months(\"start_date\",-2))\n",
    "df_add2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc7b567b-fc45-4515-bc76-91a4d3fbfcdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+-------------------+-------------------+-------------------+\n|S_no|Start_Date|  End_Date|        Add_2_years|     Add_3_quarters|        Add_5_weeks|\n+----+----------+----------+-------------------+-------------------+-------------------+\n|   1|2024-02-07|12/31/2024|2026-02-07 00:00:00|2024-11-07 00:00:00|2024-03-13 00:00:00|\n|   2|2024-02-08|11/30/2024|2026-02-08 00:00:00|2024-11-08 00:00:00|2024-03-14 00:00:00|\n|   3|2025-05-09|08/29/2025|2027-05-09 00:00:00|2026-02-09 00:00:00|2025-06-13 00:00:00|\n|   4|2025-02-10|10/30/2025|2027-02-10 00:00:00|2025-11-10 00:00:00|2025-03-17 00:00:00|\n|   5|2023-12-11|12/31/2023|2025-12-11 00:00:00|2024-09-11 00:00:00|2024-01-15 00:00:00|\n|   6|2022-01-01|12/31/2022|2024-01-01 00:00:00|2022-10-01 00:00:00|2022-02-05 00:00:00|\n|   7|2024-01-31|03/31/2024|2026-01-31 00:00:00|2024-10-31 00:00:00|2024-03-06 00:00:00|\n+----+----------+----------+-------------------+-------------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Alternate option to use date add for year, quarter,week etc\n",
    "#use expression language\n",
    "\n",
    "df_add3 = df.withColumn(\"Add_2_years\",expr(\"date_add(year,2,start_date)\"))\\\n",
    "            .withColumn(\"Add_3_quarters\",expr(\"date_add(quarter,3,start_date)\"))\\\n",
    "            .withColumn(\"Add_5_weeks\",expr(\"date_add(week,5,start_date)\"))\n",
    "df_add3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9db1b840-4c5b-4a1a-94d2-b96180757dba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+----------+\n|S_no|Start_Date|  End_Date|  Last_Day|\n+----+----------+----------+----------+\n|   1|2024-02-07|12/31/2024|2024-02-29|\n|   2|2023-02-08|11/30/2024|2023-02-28|\n|   3|2025-05-09|08/29/2025|2025-05-31|\n|   4|2025-02-10|10/30/2025|2025-02-28|\n|   5|2023-12-11|12/31/2023|2023-12-31|\n|   6|2022-01-01|12/31/2022|2022-01-31|\n|   7|2024-01-31|03/31/2024|2024-01-31|\n+----+----------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "#Last day of the Month\n",
    "df_lst = df.withColumn(\"Last_Day\",last_day(\"start_date\"))\n",
    "df_lst.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4479def-79a9-4325-a055-8ca9bce95257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+-----------+--------------------+\n|S_no|Start_Date|  End_Date|CurrentDate|    CurrentTimestamp|\n+----+----------+----------+-----------+--------------------+\n|   1|2024-02-07|12/31/2024| 2025-08-29|2025-08-29 12:17:...|\n|   2|2023-02-08|11/30/2024| 2025-08-29|2025-08-29 12:17:...|\n|   3|2025-05-09|08/29/2025| 2025-08-29|2025-08-29 12:17:...|\n|   4|2025-02-10|10/30/2025| 2025-08-29|2025-08-29 12:17:...|\n|   5|2023-12-11|12/31/2023| 2025-08-29|2025-08-29 12:17:...|\n|   6|2022-01-01|12/31/2022| 2025-08-29|2025-08-29 12:17:...|\n|   7|2024-01-31|03/31/2024| 2025-08-29|2025-08-29 12:17:...|\n+----+----------+----------+-----------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#currentdate will give the output as date only\n",
    "#currenttimestam will retun both date and time in UTC timezone\n",
    "\n",
    "df_curnt = df.withColumn(\"CurrentDate\",current_date())\\\n",
    "             .withColumn(\"CurrentTimestamp\",current_timestamp())\n",
    "df_curnt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "926efc31-e600-447c-befc-085f58767ccf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+-------------------+-------------------+-------------------+-------------------+-------------------+\n|S_no|Start_Date|  End_Date|      start_of_year|     start_of_month|      start_of_week|   start_of_quarter|       start_of_day|\n+----+----------+----------+-------------------+-------------------+-------------------+-------------------+-------------------+\n|   1|2024-02-07|12/31/2024|2024-01-01 00:00:00|2024-02-01 00:00:00|2024-02-05 00:00:00|2024-01-01 00:00:00|2024-02-07 00:00:00|\n|   2|2023-02-08|11/30/2024|2023-01-01 00:00:00|2023-02-01 00:00:00|2023-02-06 00:00:00|2023-01-01 00:00:00|2023-02-08 00:00:00|\n|   3|2025-05-09|08/29/2025|2025-01-01 00:00:00|2025-05-01 00:00:00|2025-05-05 00:00:00|2025-04-01 00:00:00|2025-05-09 00:00:00|\n|   4|2025-02-10|10/30/2025|2025-01-01 00:00:00|2025-02-01 00:00:00|2025-02-10 00:00:00|2025-01-01 00:00:00|2025-02-10 00:00:00|\n|   5|2023-12-11|12/31/2023|2023-01-01 00:00:00|2023-12-01 00:00:00|2023-12-11 00:00:00|2023-10-01 00:00:00|2023-12-11 00:00:00|\n|   6|2022-01-01|12/31/2022|2022-01-01 00:00:00|2022-01-01 00:00:00|2021-12-27 00:00:00|2022-01-01 00:00:00|2022-01-01 00:00:00|\n|   7|2024-01-31|03/31/2024|2024-01-01 00:00:00|2024-01-01 00:00:00|2024-01-29 00:00:00|2024-01-01 00:00:00|2024-01-31 00:00:00|\n+----+----------+----------+-------------------+-------------------+-------------------+-------------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#date_trunc will take you the start of the year, month,week etc..\n",
    "#synatx: date_trunc('interval','DateCol')\n",
    "#ACCEPTABLE PARAMETERS in datetrunc function\n",
    "#'year','yyyy','yy','month','mon,''mm','day','dd','hour','minute','second','week','quarter'\n",
    "\n",
    "\n",
    "df_trunc = df.withColumn(\"start_of_year\",date_trunc('year','start_date'))\\\n",
    "             .withColumn(\"start_of_month\",date_trunc('month','start_date'))\\\n",
    "             .withColumn(\"start_of_week\",date_trunc('week','start_date'))\\\n",
    "             .withColumn(\"start_of_quarter\",date_trunc('quarter','start_date'))\\\n",
    "             .withColumn(\"start_of_day\",date_trunc('day','start_date'))\n",
    "df_trunc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec2c94f5-b340-4d6d-bca8-9b0c8ba28e04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+-------------------+-------------------+-------------------+-------------------+------------+\n|S_no|start_date|  End_Date|      start_of_year|     start_of_month|      start_of_week|   start_of_quarter|start_of_day|\n+----+----------+----------+-------------------+-------------------+-------------------+-------------------+------------+\n|   1|2024-02-07|12/31/2024|2024-01-01 00:00:00|2024-02-01 00:00:00|2024-02-05 00:00:00|2024-01-01 00:00:00|  2024-02-07|\n|   2|2023-02-08|11/30/2024|2023-01-01 00:00:00|2023-02-01 00:00:00|2023-02-06 00:00:00|2023-01-01 00:00:00|  2023-02-08|\n|   3|2025-05-09|08/29/2025|2025-01-01 00:00:00|2025-05-01 00:00:00|2025-05-05 00:00:00|2025-04-01 00:00:00|  2025-05-09|\n|   4|2025-02-10|10/30/2025|2025-01-01 00:00:00|2025-02-01 00:00:00|2025-02-10 00:00:00|2025-01-01 00:00:00|  2025-02-10|\n|   5|2023-12-11|12/31/2023|2023-01-01 00:00:00|2023-12-01 00:00:00|2023-12-11 00:00:00|2023-10-01 00:00:00|  2023-12-11|\n|   6|2022-01-01|12/31/2022|2022-01-01 00:00:00|2022-01-01 00:00:00|2021-12-27 00:00:00|2022-01-01 00:00:00|  2022-01-01|\n|   7|2024-01-31|03/31/2024|2024-01-01 00:00:00|2024-01-01 00:00:00|2024-01-29 00:00:00|2024-01-01 00:00:00|  2024-01-31|\n+----+----------+----------+-------------------+-------------------+-------------------+-------------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Dateformat helps you in changing the format of the date\n",
    "#syntax: date_format('DateCol','dateformat')\n",
    "#Accepted string in date format\n",
    "# yyyy, yy, MMMM,MMM,MM, dd, hh, mm, ss\n",
    "\n",
    "# remove timestamp from above df_trunc dateformat from Start_Date column\n",
    "df_trunc = df_trunc.withColumn(\"start_of_day\",date_format(\"start_of_day\",\"yyyy-MM-dd\"))\n",
    "df_trunc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aef0ac38-f852-4738-b167-bab61cafac6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+------------+\n|S_no|Start_Date|  End_Date|MM-YY format|\n+----+----------+----------+------------+\n|   1|2024-02-07|12/31/2024|      Feb-24|\n|   2|2023-02-08|11/30/2024|      Feb-23|\n|   3|2025-05-09|08/29/2025|      May-25|\n|   4|2025-02-10|10/30/2025|      Feb-25|\n|   5|2023-12-11|12/31/2023|      Dec-23|\n|   6|2022-01-01|12/31/2022|      Jan-22|\n|   7|2024-01-31|03/31/2024|      Jan-24|\n+----+----------+----------+------------+\n\n+----+----------+----------+---------------+\n|S_no|Start_Date|  End_Date|Month-YY format|\n+----+----------+----------+---------------+\n|   1|2024-02-07|12/31/2024|    February-24|\n|   2|2023-02-08|11/30/2024|    February-23|\n|   3|2025-05-09|08/29/2025|         May-25|\n|   4|2025-02-10|10/30/2025|    February-25|\n|   5|2023-12-11|12/31/2023|    December-23|\n|   6|2022-01-01|12/31/2022|     January-22|\n|   7|2024-01-31|03/31/2024|     January-24|\n+----+----------+----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "#get teh date format in \"Aug-29\"\n",
    "df_fmt2 = df.withColumn(\"MM-YY format\",date_format(\"start_date\",\"MMM-yy\"))\n",
    "df_fmt2.show()\n",
    "#get teh date format in \"Auguest-29\"\n",
    "df_fmt3 = df.withColumn(\"Month-YY format\",date_format(\"start_date\",\"MMMM-yy\"))\n",
    "df_fmt3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d851600-1670-410a-be63-b150da3a10cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+--------------------+----+------+------+\n|S_no|Start_Date|  End_Date|   Current_timestamp|hour|minute|second|\n+----+----------+----------+--------------------+----+------+------+\n|   1|2024-02-07|12/31/2024|2025-08-29 12:31:...|  12|    31|    47|\n|   2|2023-02-08|11/30/2024|2025-08-29 12:31:...|  12|    31|    47|\n|   3|2025-05-09|08/29/2025|2025-08-29 12:31:...|  12|    31|    47|\n|   4|2025-02-10|10/30/2025|2025-08-29 12:31:...|  12|    31|    47|\n|   5|2023-12-11|12/31/2023|2025-08-29 12:31:...|  12|    31|    47|\n|   6|2022-01-01|12/31/2022|2025-08-29 12:31:...|  12|    31|    47|\n|   7|2024-01-31|03/31/2024|2025-08-29 12:31:...|  12|    31|    47|\n+----+----------+----------+--------------------+----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#get the hour, minutes,seconds from a date\n",
    "\n",
    "df2 = df.withColumn(\"Current_timestamp\", current_timestamp())\n",
    "df3 = df2.withColumn(\"hour\",hour(\"Current_timestamp\"))\\\n",
    "        .withColumn(\"minute\",minute(\"Current_timestamp\"))\\\n",
    "        .withColumn(\"second\",second(\"Current_timestamp\"))\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a9dae86-caef-441f-b127-e69174daaf08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>S_no</th><th>Start_Date</th><th>End_Date</th><th>Current_timestamp</th><th>hour</th><th>minute</th><th>second</th></tr></thead><tbody><tr><td>1</td><td>2024-02-07</td><td>12/31/2024</td><td>2025-08-29T12:33:50.904001Z</td><td>12</td><td>33</td><td>50</td></tr><tr><td>2</td><td>2023-02-08</td><td>11/30/2024</td><td>2025-08-29T12:33:50.904001Z</td><td>12</td><td>33</td><td>50</td></tr><tr><td>3</td><td>2025-05-09</td><td>08/29/2025</td><td>2025-08-29T12:33:50.904001Z</td><td>12</td><td>33</td><td>50</td></tr><tr><td>4</td><td>2025-02-10</td><td>10/30/2025</td><td>2025-08-29T12:33:50.904001Z</td><td>12</td><td>33</td><td>50</td></tr><tr><td>5</td><td>2023-12-11</td><td>12/31/2023</td><td>2025-08-29T12:33:50.904001Z</td><td>12</td><td>33</td><td>50</td></tr><tr><td>6</td><td>2022-01-01</td><td>12/31/2022</td><td>2025-08-29T12:33:50.904001Z</td><td>12</td><td>33</td><td>50</td></tr><tr><td>7</td><td>2024-01-31</td><td>03/31/2024</td><td>2025-08-29T12:33:50.904001Z</td><td>12</td><td>33</td><td>50</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "2024-02-07",
         "12/31/2024",
         "2025-08-29T12:33:50.904001Z",
         "12",
         "33",
         "50"
        ],
        [
         2,
         "2023-02-08",
         "11/30/2024",
         "2025-08-29T12:33:50.904001Z",
         "12",
         "33",
         "50"
        ],
        [
         3,
         "2025-05-09",
         "08/29/2025",
         "2025-08-29T12:33:50.904001Z",
         "12",
         "33",
         "50"
        ],
        [
         4,
         "2025-02-10",
         "10/30/2025",
         "2025-08-29T12:33:50.904001Z",
         "12",
         "33",
         "50"
        ],
        [
         5,
         "2023-12-11",
         "12/31/2023",
         "2025-08-29T12:33:50.904001Z",
         "12",
         "33",
         "50"
        ],
        [
         6,
         "2022-01-01",
         "12/31/2022",
         "2025-08-29T12:33:50.904001Z",
         "12",
         "33",
         "50"
        ],
        [
         7,
         "2024-01-31",
         "03/31/2024",
         "2025-08-29T12:33:50.904001Z",
         "12",
         "33",
         "50"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "S_no",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Start_Date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "End_Date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Current_timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "hour",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "minute",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "second",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = df.withColumn(\"Current_timestamp\", current_timestamp())\n",
    "df4 = (\n",
    "    df2.withColumn(\"hour\", date_format(\"Current_timestamp\", \"HH\"))\n",
    "       .withColumn(\"minute\", date_format(\"Current_timestamp\", \"mm\"))\n",
    "       .withColumn(\"second\", date_format(\"Current_timestamp\", \"ss\"))\n",
    ")\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d8d15f8-a62c-456c-8f8c-f78f74766477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+--------------------+---------+\n|S_no|Start_Date|  End_Date|  Current_Time_Stamp|Diff_days|\n+----+----------+----------+--------------------+---------+\n|   1|2024-02-07|12/31/2024|2025-08-29 12:37:...|      569|\n|   2|2023-02-08|11/30/2024|2025-08-29 12:37:...|      933|\n|   3|2025-05-09|08/29/2025|2025-08-29 12:37:...|      112|\n|   4|2025-02-10|10/30/2025|2025-08-29 12:37:...|      200|\n|   5|2023-12-11|12/31/2023|2025-08-29 12:37:...|      627|\n|   6|2022-01-01|12/31/2022|2025-08-29 12:37:...|     1336|\n|   7|2024-01-31|03/31/2024|2025-08-29 12:37:...|      576|\n+----+----------+----------+--------------------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "#datediff function will return the difference in the form of no of days\n",
    "\n",
    "df2 = df.withColumn(\"Current_Time_Stamp\", current_timestamp())\n",
    "df_diff = df2.withColumn(\"Diff_days\",datediff(\"Current_Time_Stamp\",\"start_date\"))\n",
    "df_diff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c81627-5aa7-4852-b87d-82453002f75b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+-------------------+--------------------+\n|S_no|Start_Date|  End_Date|       StartOfToday|  Current_Time_Stamp|\n+----+----------+----------+-------------------+--------------------+\n|   1|2024-02-07|12/31/2024|2025-08-29 00:00:00|2025-08-29 12:40:...|\n|   2|2023-02-08|11/30/2024|2025-08-29 00:00:00|2025-08-29 12:40:...|\n|   3|2025-05-09|08/29/2025|2025-08-29 00:00:00|2025-08-29 12:40:...|\n|   4|2025-02-10|10/30/2025|2025-08-29 00:00:00|2025-08-29 12:40:...|\n|   5|2023-12-11|12/31/2023|2025-08-29 00:00:00|2025-08-29 12:40:...|\n|   6|2022-01-01|12/31/2022|2025-08-29 00:00:00|2025-08-29 12:40:...|\n|   7|2024-01-31|03/31/2024|2025-08-29 00:00:00|2025-08-29 12:40:...|\n+----+----------+----------+-------------------+--------------------+\n\n+----+----------+----------+-------------------+--------------------+---------+\n|S_no|Start_Date|  End_Date|       StartOfToday|  Current_Time_Stamp|Diff_time|\n+----+----------+----------+-------------------+--------------------+---------+\n|   1|2024-02-07|12/31/2024|2025-08-29 00:00:00|2025-08-29 12:40:...|    45642|\n|   2|2023-02-08|11/30/2024|2025-08-29 00:00:00|2025-08-29 12:40:...|    45642|\n|   3|2025-05-09|08/29/2025|2025-08-29 00:00:00|2025-08-29 12:40:...|    45642|\n|   4|2025-02-10|10/30/2025|2025-08-29 00:00:00|2025-08-29 12:40:...|    45642|\n|   5|2023-12-11|12/31/2023|2025-08-29 00:00:00|2025-08-29 12:40:...|    45642|\n|   6|2022-01-01|12/31/2022|2025-08-29 00:00:00|2025-08-29 12:40:...|    45642|\n|   7|2024-01-31|03/31/2024|2025-08-29 00:00:00|2025-08-29 12:40:...|    45642|\n+----+----------+----------+-------------------+--------------------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# get the difference in time between start of todays date and current time\n",
    "\n",
    "df2 = df.withColumn(\"StartOfToday\",date_trunc(\"day\",current_timestamp()))\\\n",
    "        .withColumn(\"Current_Time_Stamp\", current_timestamp())\n",
    "df2.show()\n",
    "\n",
    "df_diff2 = df2.withColumn(\"Diff_time\",unix_timestamp(\"Current_Time_Stamp\")-unix_timestamp(\"StartOfToday\"))\n",
    "df_diff2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce07e2e0-11a3-4ae8-9d4f-e4f21d1010aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Start Date': datetime.datetime(2025, 5, 28, 12, 32), 'End Date': datetime.datetime(2025, 5, 28, 12, 32)}, {'Start Date': datetime.datetime(2025, 8, 28, 12, 32), 'End Date': datetime.datetime(2025, 8, 28, 12, 32)}]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime# create a list with start date and end date\n",
    "\n",
    "\n",
    "date_list = [\n",
    "    {\"Start Date\": datetime(2025,5,28,12,32,0,0), \"End Date\": datetime(2025,5,28,12,32,0,0)},\n",
    "    {\"Start Date\": datetime(2025,8,28,12,32,0,0), \"End Date\": datetime(2025,8,28,12,32,0,0)}\n",
    "]\n",
    "print(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59f5213a-009c-492b-ade9-8f2c5a6751ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----+\n|           End Date|         Start Date|Diff|\n+-------------------+-------------------+----+\n|2025-05-28 12:32:00|2025-05-28 12:32:00|   0|\n|2025-08-28 12:32:00|2025-08-28 12:32:00|   0|\n+-------------------+-------------------+----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, unix_timestamp\n",
    "\n",
    "#Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"Datediffexample\").getOrCreate()\n",
    "\n",
    "# Creata dataframe from the date list\n",
    "\n",
    "date_df = spark.createDataFrame(date_list)\n",
    "\n",
    "# Calculate the difference in seconds b/w start date and end date\n",
    "date_df = date_df.withColumn(\"Diff\", (unix_timestamp(col(\"End Date\")) - unix_timestamp(col(\"Start Date\"))))\n",
    "\n",
    "date_df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Expression",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}